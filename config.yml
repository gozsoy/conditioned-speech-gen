# experiment
model: k2t
experiment_name: 1sep_rep_check # e.g. 24aug_k2t_gpt2medium_maxseqlen256_batch8_8_lr2e5

# directory info
data_path: /cluster/scratch/goezsoy/nlp_lss_datasets
log_dir: logs
checkpoint_dir: /cluster/scratch/goezsoy/nlp_lss_checkpoints

# training
epochs: 3
max_seq_len: 256
batch_size: 8
gradient_accumulations: 8  # batch_size * gr_acc = effective batch size
learning_rate: 0.00002
print_iter_freq: 500
