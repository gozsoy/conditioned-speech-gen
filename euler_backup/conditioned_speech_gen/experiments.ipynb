{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from model import PrefixNet"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.manifold import TSNE, Isomap, MDS\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "\n",
    "cfg= {'batch_size':8,'prefix_len':5,'embed_size_per_token':300,'speaker_size':106,'epoch':12,'encoded':'encoded_st_p_ids','freeze_gpt':False}\n",
    "name_col= 'st_p' # st_p, parl_part, encoded_bioguide_ids\n",
    "\n",
    "model = PrefixNet(cfg)\n",
    "\n",
    "model_name=f'24may_prefix_tuning_stp_prlen{cfg[\"prefix_len\"]}_embsize{cfg[\"embed_size_per_token\"]}_speaksize{cfg[\"speaker_size\"]}_maxseqlen256_batch8_8_epoch{cfg[\"epoch\"]}.pt'\n",
    "checkpoint = torch.load('/cluster/scratch/goezsoy/nlp_lss_checkpoints/'+model_name,map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "X = model.embedding_layer.weight.detach().numpy()\n",
    "\n",
    "\n",
    "X_embedded_pca = PCA(n_components=2).fit_transform(X)\n",
    "X_embedded_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "X_embedded_mds = MDS(n_components=2).fit_transform(X)\n",
    "X_embedded_isomap = Isomap(n_components=2).fit_transform(X)\n",
    "\n",
    "speaker_labels = np.arange(0,cfg['speaker_size'])\n",
    "processed_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv')\n",
    "meta_df= processed_df[processed_df[cfg['encoded']].isin(speaker_labels)].drop_duplicates(subset=cfg['encoded'])\n",
    "\n",
    "#first plot\n",
    "group = meta_df.sort_values(by=cfg['encoded'],ascending=True, inplace=False).term_party.values\n",
    "cdict = {'Democrat': 'blue', 'Republican': 'red', 'Independent':'yellow'}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12))\n",
    "\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(X_embedded_tsne[ix,0], X_embedded_tsne[ix,1], c = cdict[g], label = g, s = 100)\n",
    "\n",
    "for i, idx in enumerate(list(speaker_labels)):\n",
    "    ax.annotate(meta_df[meta_df[cfg['encoded']]==idx][name_col].values[0], (X_embedded_tsne[i,0], X_embedded_tsne[i,1]))\n",
    "ax.legend()\n",
    "ax.set_title('tsne')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#second plot\n",
    "fig2, ax2 = plt.subplots(figsize=(12,12))\n",
    "\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax2.scatter(X_embedded_pca[ix,0], X_embedded_pca[ix,1], c = cdict[g], label = g, s = 100)\n",
    "\n",
    "for i, idx in enumerate(list(speaker_labels)):\n",
    "    ax2.annotate(meta_df[meta_df[cfg['encoded']]==idx][name_col].values[0], (X_embedded_pca[i,0], X_embedded_pca[i,1]))\n",
    "ax2.legend()\n",
    "ax2.set_title('pca')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#third plot\n",
    "fig3, ax3 = plt.subplots(figsize=(12,12))\n",
    "\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax3.scatter(X_embedded_mds[ix,0], X_embedded_mds[ix,1], c = cdict[g], label = g, s = 100)\n",
    "\n",
    "for i, idx in enumerate(list(speaker_labels)):\n",
    "    ax3.annotate(meta_df[meta_df[cfg['encoded']]==idx][name_col].values[0], (X_embedded_mds[i,0], X_embedded_mds[i,1]))\n",
    "    \n",
    "ax3.legend()\n",
    "ax3.set_title('mds')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#fourth plot\n",
    "fig4, ax4 = plt.subplots(figsize=(12,12))\n",
    "\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax4.scatter(X_embedded_isomap[ix,0], X_embedded_isomap[ix,1], c = cdict[g], label = g, s = 100)\n",
    "\n",
    "for i, idx in enumerate(list(speaker_labels)):\n",
    "    ax4.annotate(meta_df[meta_df[cfg['encoded']]==idx][name_col].values[0], (X_embedded_isomap[i,0], X_embedded_isomap[i,1]))\n",
    "    \n",
    "ax4.legend()\n",
    "ax4.set_title('isomap')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# SAVE\n",
    "\n",
    "# add perplexity score for each real sentence\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "max_word_count = 256\n",
    "\n",
    "valid_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/toy_processed_df_valid.csv')\n",
    "temp_valid_df = valid_df.iloc[:100]\n",
    "\n",
    "\n",
    "real_fake_df = pd.DataFrame(columns=['speech','label','perplexity'])\n",
    "\n",
    "real_fake_df['speech'] = temp_valid_df['speech'].map(lambda row: ' '.join(row.split()[:max_word_count]))\n",
    "real_fake_df['label'] = 1\n",
    "\n",
    "generated_texts_path = '/cluster/home/goezsoy/K2T/results/50_keywordsets_eval/finetunedgptmed_valid100_trick/Result_w_5.0_nBeams_1_nGenSent_256_nWordsPerSent_1_topP_0.9_WC_glove_maxSENTENCES.txt'\n",
    "\n",
    "file = open(generated_texts_path, 'r')\n",
    "\n",
    "temp_speech = None\n",
    "temp_perplexity = None\n",
    "\n",
    "flag_speech = False\n",
    "flag_perplexity = False\n",
    "\n",
    "for line in file:\n",
    "    if line != '\\n' and re.search(\"\\ASuccess_rate:\", line) is None and re.search(\"#.:\", line) is None:\n",
    "        if re.search(\"\\APerplexity:\", line) is not None:\n",
    "            temp_perplexity = line.split()[-1]\n",
    "            flag_perplexity = True\n",
    "        else:\n",
    "            # remove <|endoftext|> tokens generated by k2t\n",
    "            temp_speech = line.replace('<|endoftext|>','')\n",
    "\n",
    "            # if initial text is <|endoftext|> removing it leads to\n",
    "            # extra space at the start of sentence, so remove it\n",
    "            if temp_speech[0] == ' ':\n",
    "                temp_speech = temp_speech[1:]\n",
    "            flag_speech = True\n",
    "    \n",
    "    if flag_speech and flag_perplexity:\n",
    "        temp_df = pd.DataFrame.from_dict({'speech':[temp_speech],'label':[0],'perplexity':[temp_perplexity]})\n",
    "        real_fake_df = pd.concat([real_fake_df,temp_df], ignore_index=True)\n",
    "\n",
    "        flag_speech = False\n",
    "        flag_perplexity = False\n",
    "\n",
    "file.close()\n",
    "real_fake_df.to_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/real_fake_df.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import glob\n",
    "import os\n",
    "results_path = '/cluster/home/goezsoy/conditioned_speech_gen/results/shard4'\n",
    "folder_name = 'finetunedgptmed_valid10k'\n",
    "experiment_name = 'Result_w_5.0_nBeams_1_nGenSent_256_nWordsPerSent_1_topP_0.9_WC_Guar_True_glove_maxSENTENCES.txt'\n",
    "\n",
    "generated_texts_path = os.path.join(results_path,folder_name,experiment_name)\n",
    "\n",
    "os.path.exists(generated_texts_path)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# add perplexity score for each real sentence\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "\n",
    "\n",
    "max_word_count = 256\n",
    "\n",
    "valid_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df_valid.csv')\n",
    "temp_valid_df = valid_df.iloc[:500]\n",
    "\n",
    "\n",
    "real_fake_df = pd.DataFrame(columns=['speech','label','perplexity'])\n",
    "\n",
    "real_fake_df['speech'] = temp_valid_df['speech'].map(lambda row: ' '.join(row.split()[:max_word_count]))\n",
    "real_fake_df['label'] = 1\n",
    "\n",
    "\n",
    "results_path = '/cluster/home/goezsoy/conditioned_speech_gen/results'\n",
    "folder_name = 'finetunedgptmed'\n",
    "experiment_name = 'Result_w_5.0_nBeams_1_nGenSent_90_nWordsPerSent_1_topP_0.9_WC_Guar_True_glove_maxSENTENCES.txt'\n",
    "shard_list = glob.glob(os.path.join(results_path,'shard*',folder_name))\n",
    "\n",
    "for temp_shard in shard_list:\n",
    "    \n",
    "    generated_texts_path = os.path.join(temp_shard,experiment_name)\n",
    "\n",
    "    file = open(generated_texts_path, 'r')\n",
    "\n",
    "    temp_speech = None\n",
    "    temp_perplexity = None\n",
    "\n",
    "    flag_speech = False\n",
    "    flag_perplexity = False\n",
    "\n",
    "    for line in file:\n",
    "        if line != '\\n' and re.search(\"\\ASuccess_rate:\", line) is None and re.search(\"#.:\", line) is None:\n",
    "            if re.search(\"\\APerplexity:\", line) is not None:\n",
    "                temp_perplexity = line.split()[-1]\n",
    "                flag_perplexity = True\n",
    "            else:\n",
    "                # remove <|endoftext|> tokens generated by k2t\n",
    "                temp_speech = line.replace('<|endoftext|>','')\n",
    "\n",
    "                # if initial text is <|endoftext|> removing it leads to\n",
    "                # extra space at the start of sentence, so remove it\n",
    "                if temp_speech[0] == ' ':\n",
    "                    temp_speech = temp_speech[1:]\n",
    "                flag_speech = True\n",
    "        \n",
    "        if flag_speech and flag_perplexity:\n",
    "            temp_df = pd.DataFrame.from_dict({'speech':[temp_speech],'label':[0],'perplexity':[temp_perplexity]})\n",
    "            real_fake_df = pd.concat([real_fake_df,temp_df], ignore_index=True)\n",
    "\n",
    "            flag_speech = False\n",
    "            flag_perplexity = False\n",
    "\n",
    "    file.close()\n",
    "    \n",
    "real_fake_df.to_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/real_fake_df.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "real_fake_df.iloc[-6:].values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "valid_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df_valid.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-cased\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-cased\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def tokenize_function(row):\n",
    "\n",
    "    tokenizer_dict = tokenizer(row['speech'])\n",
    "    tokenizer_dict['labels'] = row['label']\n",
    "\n",
    "    return {**tokenizer_dict}\n",
    "\n",
    "\n",
    "def prepare_dataloader(df):\n",
    "\n",
    "    dataset = Dataset.from_pandas(df)\n",
    "\n",
    "    dataset = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "    dataset.set_format(type='torch', columns=['input_ids', 'attention_mask', 'labels'])\n",
    "\n",
    "    # for dynamic padding\n",
    "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer,return_tensors='pt')\n",
    "\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,collate_fn=data_collator, batch_size=32, shuffle=True, drop_last=False)\n",
    "\n",
    "    return dataloader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "real_fake_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/real_fake_df.csv')\n",
    "\n",
    "real_fake_df['speech'] = real_fake_df['speech'].map(lambda row: row.lower())\n",
    "\n",
    "# train vs test split\n",
    "X_train_valid, X_test, _, _ = train_test_split(real_fake_df.index, real_fake_df['label'], test_size=0.2, random_state=0, stratify=real_fake_df['label'])\n",
    "\n",
    "real_fake_train_valid_df = real_fake_df.iloc[X_train_valid].reset_index(drop=True)\n",
    "real_fake_test_df = real_fake_df.iloc[X_test].reset_index(drop=True)\n",
    "\n",
    "# train vs valid split\n",
    "X_train, X_valid, _, _ = train_test_split(real_fake_train_valid_df.index, real_fake_train_valid_df['label'], test_size=0.1, random_state=0, stratify= real_fake_train_valid_df['label'])\n",
    "\n",
    "real_fake_train_df = real_fake_train_valid_df.iloc[X_train].reset_index(drop=True)\n",
    "real_fake_valid_df = real_fake_train_valid_df.iloc[X_valid].reset_index(drop=True)\n",
    "\n",
    "\n",
    "train_dataloader = prepare_dataloader(real_fake_train_df)\n",
    "valid_dataloader = prepare_dataloader(real_fake_valid_df)\n",
    "test_dataloader = prepare_dataloader(real_fake_test_df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "valid_dataloader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "for b in valid_dataloader:\n",
    "    print(b)\n",
    "    break"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ground_truth = b['labels']\n",
    "\n",
    "logits = model(**b).logits\n",
    "preds = torch.argmax(logits,axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "real_probs = torch.nn.functional.softmax(logits.cpu().detach(), dim=1)[:,1]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "print(accuracy_score(ground_truth.numpy(), preds.numpy()))\n",
    "\n",
    "print(roc_auc_score(ground_truth.numpy(), real_probs.numpy()))\n",
    "\n",
    "print(average_precision_score(ground_truth.numpy(), real_probs.numpy()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import re\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import random\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import Dataset\n",
    "from transformers import DataCollatorWithPadding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, average_precision_score, roc_auc_score\n",
    "\n",
    "max_word_count = 100\n",
    "\n",
    "# put real samples\n",
    "real_fake_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/real_df_first5k.csv')\n",
    "\n",
    "# put fake samples\n",
    "results_path = '/cluster/home/goezsoy/conditioned_speech_gen/results'\n",
    "folder_name = 'finetunedgptmed_lr2e5_epoch2'\n",
    "experiment_name = 'Result_w_5.0_nBeams_1_nGenSent_128_nWordsPerSent_1_topP_0.9_WC_Guar_True_glove_maxSENTENCES.txt'\n",
    "\n",
    "print(max_word_count,folder_name,experiment_name)\n",
    "shard_list = glob.glob(os.path.join(results_path,'shard*',folder_name))\n",
    "\n",
    "\n",
    "for temp_shard in shard_list:\n",
    "    \n",
    "    generated_texts_path = os.path.join(temp_shard,experiment_name)\n",
    "\n",
    "    if os.path.exists(generated_texts_path):\n",
    "        file = open(generated_texts_path, 'r')\n",
    "\n",
    "        temp_speech = None\n",
    "        temp_perplexity = None\n",
    "\n",
    "        flag_speech = False\n",
    "        flag_perplexity = False\n",
    "\n",
    "        for line in file:\n",
    "            if line != '\\n' and re.search(\"\\ASuccess_rate:\", line) is None and re.search(\"#.:\", line) is None:\n",
    "                if re.search(\"\\APerplexity:\", line) is not None:\n",
    "                    temp_perplexity = line.split()[-1]\n",
    "                    flag_perplexity = True\n",
    "                else:\n",
    "                    # remove <|endoftext|> tokens generated by k2t\n",
    "                    temp_speech = line.replace('<|endoftext|>','')\n",
    "\n",
    "                    # if initial text is <|endoftext|> removing it leads to\n",
    "                    # extra space at the start of sentence, so remove it\n",
    "                    if temp_speech[0] == ' ':\n",
    "                        temp_speech = temp_speech[1:]\n",
    "                    flag_speech = True\n",
    "            \n",
    "            if flag_speech and flag_perplexity:\n",
    "                temp_speech = ' '.join(temp_speech.split()[:max_word_count])\n",
    "                temp_df = pd.DataFrame.from_dict({'speech':[temp_speech],'label':[0],'perplexity':[temp_perplexity]})\n",
    "                real_fake_df = pd.concat([real_fake_df,temp_df], ignore_index=True)\n",
    "\n",
    "                flag_speech = False\n",
    "                flag_perplexity = False\n",
    "\n",
    "        file.close()\n",
    "    \n",
    "real_fake_df['perplexity'] = real_fake_df['perplexity'].astype('float64')\n",
    "real_fake_df.to_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/real_fake_df.csv', index=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "real_fake_test_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/real_fake_test_df.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "real_fake_test_df[(real_fake_test_df['label']==1) & (real_fake_test_df['prediction']==0)]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df_train.csv')\n",
    "\n",
    "valid_df = pd.read_csv('/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df_valid.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "text = 'Mr. President|| human, prisoners, president'"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "# || is used for separating prompt and keywords\n",
    "intext_keyword_list = list(line.strip().split('|| '))\n",
    "intext = intext_keyword_list[0]\n",
    "keyword_list = list(intext_keyword_list[1].split(\", \"))\n",
    "intext,keyword_list"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Mr. President', ['human', 'prisoners', 'president'])"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "line = 'Mr. President, human, prisoners, president'\n",
    "intext_keyword_list = list(line.strip().split(\", \"))\n",
    "intext_keyword_list[0],intext_keyword_list[1:]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "('Mr. President', ['human', 'prisoners', 'president'])"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.13 64-bit ('cond_text_gen_project': conda)"
  },
  "interpreter": {
   "hash": "7918bf550cc222160dde757c7164fa6a3057e939eb504426b669afaa98f6c6cb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}