INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 100, 'batch_size': 16, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 100, 'batch_size': 8, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 100, 'batch_size': 4, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 100, 'batch_size': 2, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 2.7830, train_perplexity: 23.3906
INFO:root:epoch: 1, train_loss: 1.9207, train_perplexity: 7.2377
INFO:root:epoch: 2, train_loss: 1.5483, train_perplexity: 4.9122
INFO:root:epoch: 3, train_loss: 1.2429, train_perplexity: 3.5945
INFO:root:epoch: 4, train_loss: 0.9736, train_perplexity: 2.7296
INFO:root:epoch: 5, train_loss: 0.7427, train_perplexity: 2.1464
INFO:root:epoch: 6, train_loss: 0.5406, train_perplexity: 1.7440
INFO:root:epoch: 7, train_loss: 0.3821, train_perplexity: 1.4814
INFO:root:epoch: 8, train_loss: 0.2699, train_perplexity: 1.3180
INFO:root:epoch: 9, train_loss: 0.2215, train_perplexity: 1.2528
INFO:root:epoch: 10, train_loss: 0.2040, train_perplexity: 1.2298
INFO:root:epoch: 11, train_loss: 0.2098, train_perplexity: 1.2377
INFO:root:epoch: 12, train_loss: 0.1786, train_perplexity: 1.1971
INFO:root:epoch: 13, train_loss: 0.1178, train_perplexity: 1.1256
INFO:root:epoch: 14, train_loss: 0.0765, train_perplexity: 1.0797
INFO:root:epoch: 15, train_loss: 0.0547, train_perplexity: 1.0564
INFO:root:epoch: 16, train_loss: 0.0383, train_perplexity: 1.0392
INFO:root:epoch: 17, train_loss: 0.0300, train_perplexity: 1.0305
INFO:root:epoch: 18, train_loss: 0.0239, train_perplexity: 1.0242
INFO:root:epoch: 19, train_loss: 0.0225, train_perplexity: 1.0228
INFO:root:epoch: 20, train_loss: 0.0210, train_perplexity: 1.0212
INFO:root:epoch: 21, train_loss: 0.0215, train_perplexity: 1.0218
INFO:root:epoch: 22, train_loss: 0.0197, train_perplexity: 1.0199
INFO:root:epoch: 23, train_loss: 0.0196, train_perplexity: 1.0199
INFO:root:epoch: 24, train_loss: 0.0179, train_perplexity: 1.0181
INFO:root:epoch: 25, train_loss: 0.0170, train_perplexity: 1.0172
INFO:root:epoch: 26, train_loss: 0.0165, train_perplexity: 1.0166
INFO:root:epoch: 27, train_loss: 0.0160, train_perplexity: 1.0161
INFO:root:epoch: 28, train_loss: 0.0156, train_perplexity: 1.0158
INFO:root:epoch: 29, train_loss: 0.0154, train_perplexity: 1.0156
INFO:root:epoch: 30, train_loss: 0.0149, train_perplexity: 1.0151
INFO:root:epoch: 31, train_loss: 0.0147, train_perplexity: 1.0148
INFO:root:epoch: 32, train_loss: 0.0146, train_perplexity: 1.0148
INFO:root:epoch: 33, train_loss: 0.0143, train_perplexity: 1.0144
INFO:root:epoch: 34, train_loss: 0.0143, train_perplexity: 1.0145
INFO:root:epoch: 35, train_loss: 0.0139, train_perplexity: 1.0140
INFO:root:epoch: 36, train_loss: 0.0139, train_perplexity: 1.0140
INFO:root:epoch: 37, train_loss: 0.0138, train_perplexity: 1.0139
INFO:root:epoch: 38, train_loss: 0.0135, train_perplexity: 1.0136
INFO:root:epoch: 39, train_loss: 0.0136, train_perplexity: 1.0137
INFO:root:epoch: 40, train_loss: 0.0135, train_perplexity: 1.0136
INFO:root:epoch: 41, train_loss: 0.0133, train_perplexity: 1.0133
INFO:root:epoch: 42, train_loss: 0.0131, train_perplexity: 1.0132
INFO:root:epoch: 43, train_loss: 0.0131, train_perplexity: 1.0131
INFO:root:epoch: 44, train_loss: 0.0129, train_perplexity: 1.0130
INFO:root:epoch: 45, train_loss: 0.0131, train_perplexity: 1.0132
INFO:root:epoch: 46, train_loss: 0.0127, train_perplexity: 1.0127
INFO:root:epoch: 47, train_loss: 0.0128, train_perplexity: 1.0129
INFO:root:epoch: 48, train_loss: 0.0126, train_perplexity: 1.0127
INFO:root:epoch: 49, train_loss: 0.0126, train_perplexity: 1.0127
INFO:root:epoch: 50, train_loss: 0.0126, train_perplexity: 1.0127
INFO:root:epoch: 51, train_loss: 0.0126, train_perplexity: 1.0127
INFO:root:epoch: 52, train_loss: 0.0124, train_perplexity: 1.0124
INFO:root:epoch: 53, train_loss: 0.0123, train_perplexity: 1.0124
INFO:root:epoch: 54, train_loss: 0.0122, train_perplexity: 1.0123
INFO:root:epoch: 55, train_loss: 0.0122, train_perplexity: 1.0123
INFO:root:epoch: 56, train_loss: 0.0121, train_perplexity: 1.0122
INFO:root:epoch: 57, train_loss: 0.0121, train_perplexity: 1.0122
INFO:root:epoch: 58, train_loss: 0.0123, train_perplexity: 1.0124
INFO:root:epoch: 59, train_loss: 0.0123, train_perplexity: 1.0124
INFO:root:epoch: 60, train_loss: 0.0121, train_perplexity: 1.0121
INFO:root:epoch: 61, train_loss: 0.0121, train_perplexity: 1.0122
INFO:root:epoch: 62, train_loss: 0.0120, train_perplexity: 1.0121
INFO:root:epoch: 63, train_loss: 0.0121, train_perplexity: 1.0121
INFO:root:epoch: 64, train_loss: 0.0120, train_perplexity: 1.0121
INFO:root:epoch: 65, train_loss: 0.0120, train_perplexity: 1.0121
INFO:root:epoch: 66, train_loss: 0.0119, train_perplexity: 1.0120
INFO:root:epoch: 67, train_loss: 0.0120, train_perplexity: 1.0120
INFO:root:epoch: 68, train_loss: 0.0117, train_perplexity: 1.0118
INFO:root:epoch: 69, train_loss: 0.0118, train_perplexity: 1.0118
INFO:root:epoch: 70, train_loss: 0.0114, train_perplexity: 1.0115
INFO:root:epoch: 71, train_loss: 0.0117, train_perplexity: 1.0118
INFO:root:epoch: 72, train_loss: 0.0115, train_perplexity: 1.0116
INFO:root:epoch: 73, train_loss: 0.0117, train_perplexity: 1.0118
INFO:root:epoch: 74, train_loss: 0.0114, train_perplexity: 1.0114
INFO:root:epoch: 75, train_loss: 0.0116, train_perplexity: 1.0116
INFO:root:epoch: 76, train_loss: 0.0113, train_perplexity: 1.0114
INFO:root:epoch: 77, train_loss: 0.0116, train_perplexity: 1.0116
INFO:root:epoch: 78, train_loss: 0.0112, train_perplexity: 1.0113
INFO:root:epoch: 79, train_loss: 0.0115, train_perplexity: 1.0116
INFO:root:epoch: 80, train_loss: 0.0112, train_perplexity: 1.0112
INFO:root:epoch: 81, train_loss: 0.0114, train_perplexity: 1.0115
INFO:root:epoch: 82, train_loss: 0.0111, train_perplexity: 1.0112
INFO:root:epoch: 83, train_loss: 0.0114, train_perplexity: 1.0114
INFO:root:epoch: 84, train_loss: 0.0111, train_perplexity: 1.0111
INFO:root:epoch: 85, train_loss: 0.0113, train_perplexity: 1.0114
INFO:root:epoch: 86, train_loss: 0.0110, train_perplexity: 1.0111
INFO:root:epoch: 87, train_loss: 0.0113, train_perplexity: 1.0113
INFO:root:epoch: 88, train_loss: 0.0110, train_perplexity: 1.0111
INFO:root:epoch: 89, train_loss: 0.0112, train_perplexity: 1.0113
INFO:root:epoch: 90, train_loss: 0.0110, train_perplexity: 1.0110
INFO:root:epoch: 91, train_loss: 0.0112, train_perplexity: 1.0113
INFO:root:epoch: 92, train_loss: 0.0109, train_perplexity: 1.0110
INFO:root:epoch: 93, train_loss: 0.0112, train_perplexity: 1.0112
INFO:root:epoch: 94, train_loss: 0.0109, train_perplexity: 1.0110
INFO:root:epoch: 95, train_loss: 0.0111, train_perplexity: 1.0112
INFO:root:epoch: 96, train_loss: 0.0109, train_perplexity: 1.0109
INFO:root:epoch: 97, train_loss: 0.0111, train_perplexity: 1.0112
INFO:root:epoch: 98, train_loss: 0.0108, train_perplexity: 1.0109
INFO:root:epoch: 99, train_loss: 0.0111, train_perplexity: 1.0111
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 100, 'max_seq_len': 20, 'batch_size': 32, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.2555, train_perplexity: 92.7538
INFO:root:epoch: 1, train_loss: 2.4399, train_perplexity: 12.8004
INFO:root:epoch: 2, train_loss: 1.7008, train_perplexity: 6.0496
INFO:root:epoch: 3, train_loss: 1.3300, train_perplexity: 4.2188
INFO:root:epoch: 4, train_loss: 1.0574, train_perplexity: 3.2267
INFO:root:epoch: 5, train_loss: 0.8545, train_perplexity: 2.6248
INFO:root:epoch: 6, train_loss: 0.6908, train_perplexity: 2.1861
INFO:root:epoch: 7, train_loss: 0.5828, train_perplexity: 1.9177
INFO:root:epoch: 8, train_loss: 0.4785, train_perplexity: 1.6890
INFO:root:epoch: 9, train_loss: 0.4002, train_perplexity: 1.5386
INFO:root:epoch: 10, train_loss: 0.3471, train_perplexity: 1.4460
INFO:root:epoch: 11, train_loss: 0.3014, train_perplexity: 1.3716
INFO:root:epoch: 12, train_loss: 0.2652, train_perplexity: 1.3150
INFO:root:epoch: 13, train_loss: 0.2342, train_perplexity: 1.2704
INFO:root:epoch: 14, train_loss: 0.2120, train_perplexity: 1.2400
INFO:root:epoch: 15, train_loss: 0.1945, train_perplexity: 1.2174
INFO:root:epoch: 16, train_loss: 0.1835, train_perplexity: 1.2038
INFO:root:epoch: 17, train_loss: 0.1763, train_perplexity: 1.1948
INFO:root:epoch: 18, train_loss: 0.1706, train_perplexity: 1.1875
INFO:root:epoch: 19, train_loss: 0.1658, train_perplexity: 1.1814
INFO:root:epoch: 20, train_loss: 0.1607, train_perplexity: 1.1754
INFO:root:epoch: 21, train_loss: 0.1601, train_perplexity: 1.1747
INFO:root:epoch: 22, train_loss: 0.1580, train_perplexity: 1.1721
INFO:root:epoch: 23, train_loss: 0.1560, train_perplexity: 1.1697
INFO:root:epoch: 24, train_loss: 0.1534, train_perplexity: 1.1666
INFO:root:epoch: 25, train_loss: 0.1531, train_perplexity: 1.1662
INFO:root:epoch: 26, train_loss: 0.1511, train_perplexity: 1.1639
INFO:root:epoch: 27, train_loss: 0.1508, train_perplexity: 1.1635
INFO:root:epoch: 28, train_loss: 0.1506, train_perplexity: 1.1632
INFO:root:epoch: 29, train_loss: 0.1495, train_perplexity: 1.1619
INFO:root:epoch: 30, train_loss: 0.1494, train_perplexity: 1.1618
INFO:root:epoch: 31, train_loss: 0.1489, train_perplexity: 1.1612
INFO:root:epoch: 32, train_loss: 0.1484, train_perplexity: 1.1606
INFO:root:epoch: 33, train_loss: 0.1481, train_perplexity: 1.1603
INFO:root:epoch: 34, train_loss: 0.1480, train_perplexity: 1.1602
INFO:root:epoch: 35, train_loss: 0.1481, train_perplexity: 1.1603
INFO:root:epoch: 36, train_loss: 0.1478, train_perplexity: 1.1600
INFO:root:epoch: 37, train_loss: 0.1475, train_perplexity: 1.1595
INFO:root:epoch: 38, train_loss: 0.1474, train_perplexity: 1.1594
INFO:root:epoch: 39, train_loss: 0.1471, train_perplexity: 1.1592
INFO:root:epoch: 40, train_loss: 0.1472, train_perplexity: 1.1592
INFO:root:epoch: 41, train_loss: 0.1471, train_perplexity: 1.1591
INFO:root:epoch: 42, train_loss: 0.1471, train_perplexity: 1.1591
INFO:root:epoch: 43, train_loss: 0.1470, train_perplexity: 1.1589
INFO:root:epoch: 44, train_loss: 0.1468, train_perplexity: 1.1587
INFO:root:epoch: 45, train_loss: 0.1468, train_perplexity: 1.1588
INFO:root:epoch: 46, train_loss: 0.1467, train_perplexity: 1.1587
INFO:root:epoch: 47, train_loss: 0.1467, train_perplexity: 1.1587
INFO:root:epoch: 48, train_loss: 0.1466, train_perplexity: 1.1585
INFO:root:epoch: 49, train_loss: 0.1465, train_perplexity: 1.1584
INFO:root:epoch: 50, train_loss: 0.1467, train_perplexity: 1.1586
INFO:root:epoch: 51, train_loss: 0.1466, train_perplexity: 1.1585
INFO:root:epoch: 52, train_loss: 0.1471, train_perplexity: 1.1591
INFO:root:epoch: 53, train_loss: 0.1466, train_perplexity: 1.1585
INFO:root:epoch: 54, train_loss: 0.1463, train_perplexity: 1.1581
INFO:root:epoch: 55, train_loss: 0.1467, train_perplexity: 1.1586
INFO:root:epoch: 56, train_loss: 0.1464, train_perplexity: 1.1583
INFO:root:epoch: 57, train_loss: 0.1469, train_perplexity: 1.1589
INFO:root:epoch: 58, train_loss: 0.1469, train_perplexity: 1.1589
INFO:root:epoch: 59, train_loss: 0.1470, train_perplexity: 1.1590
INFO:root:epoch: 60, train_loss: 0.1464, train_perplexity: 1.1583
INFO:root:epoch: 61, train_loss: 0.1462, train_perplexity: 1.1581
INFO:root:epoch: 62, train_loss: 0.1464, train_perplexity: 1.1583
INFO:root:epoch: 63, train_loss: 0.1459, train_perplexity: 1.1577
INFO:root:epoch: 64, train_loss: 0.1463, train_perplexity: 1.1582
INFO:root:epoch: 65, train_loss: 0.1461, train_perplexity: 1.1579
INFO:root:epoch: 66, train_loss: 0.1460, train_perplexity: 1.1579
INFO:root:epoch: 67, train_loss: 0.1461, train_perplexity: 1.1579
INFO:root:epoch: 68, train_loss: 0.1459, train_perplexity: 1.1577
INFO:root:epoch: 69, train_loss: 0.1460, train_perplexity: 1.1578
INFO:root:epoch: 70, train_loss: 0.1460, train_perplexity: 1.1577
INFO:root:epoch: 71, train_loss: 0.1458, train_perplexity: 1.1576
INFO:root:epoch: 72, train_loss: 0.1460, train_perplexity: 1.1578
INFO:root:epoch: 73, train_loss: 0.1458, train_perplexity: 1.1576
INFO:root:epoch: 74, train_loss: 0.1459, train_perplexity: 1.1577
INFO:root:epoch: 75, train_loss: 0.1459, train_perplexity: 1.1576
INFO:root:epoch: 76, train_loss: 0.1459, train_perplexity: 1.1576
INFO:root:epoch: 77, train_loss: 0.1459, train_perplexity: 1.1577
INFO:root:epoch: 78, train_loss: 0.1459, train_perplexity: 1.1577
INFO:root:epoch: 79, train_loss: 0.1459, train_perplexity: 1.1577
INFO:root:epoch: 80, train_loss: 0.1460, train_perplexity: 1.1578
INFO:root:epoch: 81, train_loss: 0.1458, train_perplexity: 1.1576
INFO:root:epoch: 82, train_loss: 0.1462, train_perplexity: 1.1581
INFO:root:epoch: 83, train_loss: 0.1458, train_perplexity: 1.1576
INFO:root:epoch: 84, train_loss: 0.1460, train_perplexity: 1.1578
INFO:root:epoch: 85, train_loss: 0.1457, train_perplexity: 1.1574
INFO:root:epoch: 86, train_loss: 0.1459, train_perplexity: 1.1576
INFO:root:epoch: 87, train_loss: 0.1456, train_perplexity: 1.1573
INFO:root:epoch: 88, train_loss: 0.1458, train_perplexity: 1.1576
INFO:root:epoch: 89, train_loss: 0.1456, train_perplexity: 1.1573
INFO:root:epoch: 90, train_loss: 0.1458, train_perplexity: 1.1575
INFO:root:epoch: 91, train_loss: 0.1456, train_perplexity: 1.1573
INFO:root:epoch: 92, train_loss: 0.1457, train_perplexity: 1.1575
INFO:root:epoch: 93, train_loss: 0.1455, train_perplexity: 1.1572
INFO:root:epoch: 94, train_loss: 0.1456, train_perplexity: 1.1574
INFO:root:epoch: 95, train_loss: 0.1455, train_perplexity: 1.1572
INFO:root:epoch: 96, train_loss: 0.1456, train_perplexity: 1.1573
INFO:root:epoch: 97, train_loss: 0.1454, train_perplexity: 1.1571
INFO:root:epoch: 98, train_loss: 0.1455, train_perplexity: 1.1572
INFO:root:epoch: 99, train_loss: 0.1454, train_perplexity: 1.1571
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 5, 'max_seq_len': 512, 'batch_size': 8, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 5, 'max_seq_len': 512, 'batch_size': 2, 'learning_rate': 0.0001, 'early_stopping': True, 'lr_scheduling': True, 'do_sample': True, 'temperature': 0.9, 'max_length': 200}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 2048, 'batch_size': 4, 'gradient_accumulations': 16, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 128, 'batch_size': 2, 'gradient_accumulations': 16, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 3.8788, train_perplexity: 64.8457
INFO:root:epoch: 1, train_loss: 3.8487, train_perplexity: 63.9834
INFO:root:epoch: 2, train_loss: 3.1060, train_perplexity: 23.6509
INFO:root:epoch: 3, train_loss: 2.7945, train_perplexity: 17.3915
INFO:root:epoch: 4, train_loss: 2.6079, train_perplexity: 14.3790
INFO:root:epoch: 5, train_loss: 2.3896, train_perplexity: 11.4929
INFO:root:epoch: 6, train_loss: 2.2393, train_perplexity: 9.8552
INFO:root:epoch: 7, train_loss: 2.1191, train_perplexity: 8.7116
INFO:root:epoch: 8, train_loss: 1.9788, train_perplexity: 7.5403
INFO:root:epoch: 9, train_loss: 1.8521, train_perplexity: 6.6210
INFO:root:epoch: 10, train_loss: 1.7351, train_perplexity: 5.8712
INFO:root:epoch: 11, train_loss: 1.6309, train_perplexity: 5.2774
INFO:root:epoch: 12, train_loss: 1.5281, train_perplexity: 4.7496
INFO:root:epoch: 13, train_loss: 1.4206, train_perplexity: 4.2542
INFO:root:epoch: 14, train_loss: 1.3161, train_perplexity: 3.8218
INFO:root:epoch: 15, train_loss: 1.2184, train_perplexity: 3.4571
INFO:root:epoch: 16, train_loss: 1.1300, train_perplexity: 3.1579
INFO:root:epoch: 17, train_loss: 1.0435, train_perplexity: 2.8902
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 4, 'gradient_accumulations': 16, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 1, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 2, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 3, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 4, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 5, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 6, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 7, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 8, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 9, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 10, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 11, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 12, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 13, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 14, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 15, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 16, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 17, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 18, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 19, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 20, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 21, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 22, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 23, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 24, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 25, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 26, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 27, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 28, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 29, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 30, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 31, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 32, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 33, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 34, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 35, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 36, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 37, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 38, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 39, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 40, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 41, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 42, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 43, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 44, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 45, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 46, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 47, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 48, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 49, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 8, 'gradient_accumulations': 16, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 4, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 1, train_loss: 4.8981, train_perplexity: 273.0245
INFO:root:epoch: 2, train_loss: 2.6603, train_perplexity: 15.5901
INFO:root:epoch: 3, train_loss: 2.1769, train_perplexity: 9.2604
INFO:root:epoch: 4, train_loss: 2.2365, train_perplexity: 9.7845
INFO:root:epoch: 5, train_loss: 2.2183, train_perplexity: 9.5666
INFO:root:epoch: 6, train_loss: 2.1277, train_perplexity: 8.7120
INFO:root:epoch: 7, train_loss: 2.0218, train_perplexity: 7.8235
INFO:root:epoch: 8, train_loss: 1.8971, train_perplexity: 6.8925
INFO:root:epoch: 9, train_loss: 1.7920, train_perplexity: 6.1934
INFO:root:epoch: 10, train_loss: 1.7171, train_perplexity: 5.7393
INFO:root:epoch: 11, train_loss: 1.6684, train_perplexity: 5.4624
INFO:root:epoch: 12, train_loss: 1.6309, train_perplexity: 5.2566
INFO:root:epoch: 13, train_loss: 1.5929, train_perplexity: 5.0545
INFO:root:epoch: 14, train_loss: 1.5541, train_perplexity: 4.8557
INFO:root:epoch: 15, train_loss: 1.5142, train_perplexity: 4.6607
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 4, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4620, train_perplexity: 323.4857
INFO:root:epoch: 1, train_loss: 4.8981, train_perplexity: 273.0245
INFO:root:epoch: 2, train_loss: 2.6603, train_perplexity: 15.5901
INFO:root:epoch: 3, train_loss: 2.1769, train_perplexity: 9.2604
INFO:root:epoch: 4, train_loss: 2.2365, train_perplexity: 9.7845
INFO:root:epoch: 5, train_loss: 2.2183, train_perplexity: 9.5666
INFO:root:epoch: 6, train_loss: 2.1277, train_perplexity: 8.7120
INFO:root:epoch: 7, train_loss: 2.0218, train_perplexity: 7.8235
INFO:root:epoch: 8, train_loss: 1.8971, train_perplexity: 6.8925
INFO:root:epoch: 9, train_loss: 1.7920, train_perplexity: 6.1934
INFO:root:epoch: 10, train_loss: 1.7171, train_perplexity: 5.7393
INFO:root:epoch: 11, train_loss: 1.6684, train_perplexity: 5.4624
INFO:root:epoch: 12, train_loss: 1.6309, train_perplexity: 5.2566
INFO:root:epoch: 13, train_loss: 1.5929, train_perplexity: 5.0545
INFO:root:epoch: 14, train_loss: 1.5541, train_perplexity: 4.8557
INFO:root:epoch: 15, train_loss: 1.5142, train_perplexity: 4.6607
INFO:root:epoch: 16, train_loss: 1.4731, train_perplexity: 4.4687
INFO:root:epoch: 17, train_loss: 1.4320, train_perplexity: 4.2848
INFO:root:epoch: 18, train_loss: 1.3916, train_perplexity: 4.1119
INFO:root:epoch: 19, train_loss: 1.3522, train_perplexity: 3.9498
INFO:root:epoch: 20, train_loss: 1.3150, train_perplexity: 3.8023
INFO:root:epoch: 21, train_loss: 1.2804, train_perplexity: 3.6708
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 4, 'gradient_accumulations': 16, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 3.8750, train_perplexity: 101.2567
INFO:root:epoch: 1, train_loss: 2.1320, train_perplexity: 9.0536
INFO:root:epoch: 2, train_loss: 1.7739, train_perplexity: 6.1520
INFO:root:epoch: 3, train_loss: 1.5067, train_perplexity: 4.6104
INFO:root:epoch: 4, train_loss: 1.3234, train_perplexity: 3.8177
INFO:root:epoch: 5, train_loss: 1.1642, train_perplexity: 3.2440
INFO:root:epoch: 6, train_loss: 1.0154, train_perplexity: 2.7892
INFO:root:epoch: 7, train_loss: 0.8731, train_perplexity: 2.4157
INFO:root:epoch: 8, train_loss: 0.7358, train_perplexity: 2.1033
INFO:root:epoch: 9, train_loss: 0.6055, train_perplexity: 1.8445
INFO:root:epoch: 10, train_loss: 0.4836, train_perplexity: 1.6311
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 1, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 2, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 3, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 4, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 5, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 6, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 7, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 8, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 9, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 10, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 11, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 12, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 13, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 14, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 15, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 16, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 17, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 18, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 19, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 20, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 21, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 22, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 23, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 24, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 25, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 26, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 27, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 28, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 29, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 30, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 31, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 1, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 2, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 3, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 4, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 5, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 6, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 7, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 8, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 9, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 10, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 11, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 12, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 13, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 14, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 15, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 16, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 17, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 18, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 19, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 20, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 21, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 22, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 23, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 24, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 25, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 26, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 27, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 28, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 29, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 30, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 1, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 2, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 3, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 4, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 5, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 6, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 7, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 8, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 9, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 10, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 11, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 12, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 13, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 14, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 15, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 16, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 17, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 18, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 19, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 20, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 21, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 22, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 23, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 24, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 25, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 26, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 27, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 28, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 29, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 30, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 31, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 1, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 2, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 3, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 4, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 5, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 6, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 7, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 8, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 9, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 10, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 11, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 12, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 13, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 14, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 15, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 16, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 17, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 18, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 19, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 20, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 21, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 22, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 23, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 24, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 25, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 26, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 27, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 28, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 29, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 30, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 31, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 32, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 33, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 34, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 35, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 36, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 37, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 38, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 39, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 40, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 41, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 42, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 43, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 44, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 45, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 46, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 47, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 48, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 49, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4034, train_perplexity: 141.4896
INFO:root:epoch: 1, train_loss: 2.9202, train_perplexity: 19.9289
INFO:root:epoch: 2, train_loss: 2.2855, train_perplexity: 9.9420
INFO:root:epoch: 3, train_loss: 1.9764, train_perplexity: 7.2836
INFO:root:epoch: 4, train_loss: 1.7388, train_perplexity: 5.7301
INFO:root:epoch: 5, train_loss: 1.5239, train_perplexity: 4.6153
INFO:root:epoch: 6, train_loss: 1.3223, train_perplexity: 3.7695
INFO:root:epoch: 7, train_loss: 1.1381, train_perplexity: 3.1336
INFO:root:epoch: 8, train_loss: 0.9623, train_perplexity: 2.6268
INFO:root:epoch: 9, train_loss: 0.7983, train_perplexity: 2.2287
INFO:root:epoch: 10, train_loss: 0.6455, train_perplexity: 1.9119
INFO:root:epoch: 11, train_loss: 0.5062, train_perplexity: 1.6623
INFO:root:epoch: 12, train_loss: 0.3847, train_perplexity: 1.4712
INFO:root:epoch: 13, train_loss: 0.2838, train_perplexity: 1.3291
INFO:root:epoch: 14, train_loss: 0.2067, train_perplexity: 1.2301
INFO:root:epoch: 15, train_loss: 0.1487, train_perplexity: 1.1605
INFO:root:epoch: 16, train_loss: 0.1077, train_perplexity: 1.1138
INFO:root:epoch: 17, train_loss: 0.0796, train_perplexity: 1.0829
INFO:root:epoch: 18, train_loss: 0.0605, train_perplexity: 1.0624
INFO:root:epoch: 19, train_loss: 0.0485, train_perplexity: 1.0498
INFO:root:epoch: 20, train_loss: 0.0414, train_perplexity: 1.0422
INFO:root:epoch: 21, train_loss: 0.0355, train_perplexity: 1.0362
INFO:root:epoch: 22, train_loss: 0.0315, train_perplexity: 1.0321
INFO:root:epoch: 23, train_loss: 0.0291, train_perplexity: 1.0296
INFO:root:epoch: 24, train_loss: 0.0266, train_perplexity: 1.0269
INFO:root:epoch: 25, train_loss: 0.0250, train_perplexity: 1.0253
INFO:root:epoch: 26, train_loss: 0.0236, train_perplexity: 1.0239
INFO:root:epoch: 27, train_loss: 0.0226, train_perplexity: 1.0228
INFO:root:epoch: 28, train_loss: 0.0219, train_perplexity: 1.0222
INFO:root:epoch: 29, train_loss: 0.0211, train_perplexity: 1.0213
INFO:root:epoch: 30, train_loss: 0.0204, train_perplexity: 1.0207
INFO:root:epoch: 31, train_loss: 0.0200, train_perplexity: 1.0202
INFO:root:epoch: 32, train_loss: 0.0195, train_perplexity: 1.0197
INFO:root:epoch: 33, train_loss: 0.0190, train_perplexity: 1.0192
INFO:root:epoch: 34, train_loss: 0.0186, train_perplexity: 1.0187
INFO:root:epoch: 35, train_loss: 0.0183, train_perplexity: 1.0185
INFO:root:epoch: 36, train_loss: 0.0178, train_perplexity: 1.0180
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4034, train_perplexity: 141.4896
INFO:root:epoch: 1, train_loss: 2.9202, train_perplexity: 19.9289
INFO:root:epoch: 2, train_loss: 2.2855, train_perplexity: 9.9420
INFO:root:epoch: 3, train_loss: 1.9764, train_perplexity: 7.2836
INFO:root:epoch: 4, train_loss: 1.7388, train_perplexity: 5.7301
INFO:root:epoch: 5, train_loss: 1.5239, train_perplexity: 4.6153
INFO:root:epoch: 6, train_loss: 1.3223, train_perplexity: 3.7695
INFO:root:epoch: 7, train_loss: 1.1381, train_perplexity: 3.1336
INFO:root:epoch: 8, train_loss: 0.9623, train_perplexity: 2.6268
INFO:root:epoch: 9, train_loss: 0.7983, train_perplexity: 2.2287
INFO:root:epoch: 10, train_loss: 0.6455, train_perplexity: 1.9119
INFO:root:epoch: 11, train_loss: 0.5062, train_perplexity: 1.6623
INFO:root:epoch: 12, train_loss: 0.3847, train_perplexity: 1.4712
INFO:root:epoch: 13, train_loss: 0.2838, train_perplexity: 1.3291
INFO:root:epoch: 14, train_loss: 0.2067, train_perplexity: 1.2301
INFO:root:epoch: 15, train_loss: 0.1487, train_perplexity: 1.1605
INFO:root:epoch: 16, train_loss: 0.1077, train_perplexity: 1.1138
INFO:root:epoch: 17, train_loss: 0.0796, train_perplexity: 1.0829
INFO:root:epoch: 18, train_loss: 0.0605, train_perplexity: 1.0624
INFO:root:epoch: 19, train_loss: 0.0485, train_perplexity: 1.0498
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4034, train_perplexity: 141.4896
INFO:root:epoch: 1, train_loss: 2.9202, train_perplexity: 19.9289
INFO:root:epoch: 2, train_loss: 2.2855, train_perplexity: 9.9420
INFO:root:epoch: 3, train_loss: 1.9764, train_perplexity: 7.2836
INFO:root:epoch: 4, train_loss: 1.7388, train_perplexity: 5.7301
INFO:root:epoch: 5, train_loss: 1.5239, train_perplexity: 4.6153
INFO:root:epoch: 6, train_loss: 1.3223, train_perplexity: 3.7695
INFO:root:epoch: 7, train_loss: 1.1381, train_perplexity: 3.1336
INFO:root:epoch: 8, train_loss: 0.9623, train_perplexity: 2.6268
INFO:root:epoch: 9, train_loss: 0.7983, train_perplexity: 2.2287
INFO:root:epoch: 10, train_loss: 0.6455, train_perplexity: 1.9119
INFO:root:epoch: 11, train_loss: 0.5062, train_perplexity: 1.6623
INFO:root:epoch: 12, train_loss: 0.3847, train_perplexity: 1.4712
INFO:root:epoch: 13, train_loss: 0.2838, train_perplexity: 1.3291
INFO:root:epoch: 14, train_loss: 0.2067, train_perplexity: 1.2301
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4034, train_perplexity: 141.4896
INFO:root:epoch: 1, train_loss: 2.9202, train_perplexity: 19.9289
INFO:root:epoch: 2, train_loss: 2.2855, train_perplexity: 9.9420
INFO:root:epoch: 3, train_loss: 1.9764, train_perplexity: 7.2836
INFO:root:epoch: 4, train_loss: 1.7388, train_perplexity: 5.7301
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4034, train_perplexity: 141.4896
INFO:root:epoch: 1, train_loss: 2.9202, train_perplexity: 19.9289
INFO:root:epoch: 2, train_loss: 2.2855, train_perplexity: 9.9420
INFO:root:epoch: 3, train_loss: 1.9764, train_perplexity: 7.2836
INFO:root:epoch: 4, train_loss: 1.7388, train_perplexity: 5.7301
INFO:root:epoch: 5, train_loss: 1.5239, train_perplexity: 4.6153
INFO:root:epoch: 6, train_loss: 1.3223, train_perplexity: 3.7695
INFO:root:epoch: 7, train_loss: 1.1381, train_perplexity: 3.1336
INFO:root:epoch: 8, train_loss: 0.9623, train_perplexity: 2.6268
INFO:root:epoch: 9, train_loss: 0.7983, train_perplexity: 2.2287
INFO:root:epoch: 10, train_loss: 0.6455, train_perplexity: 1.9119
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 1, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 2, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 3, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 4, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 5, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 6, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 7, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 8, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 9, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 10, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 11, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 12, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 13, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 14, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 15, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 16, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 17, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 18, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 19, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 20, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 21, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 22, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 23, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 24, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 25, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 26, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 27, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 28, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 29, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 30, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 31, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 32, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 33, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 34, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 35, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 36, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 37, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 38, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 39, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 40, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 41, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 42, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 43, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 44, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 45, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 46, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 47, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 48, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:epoch: 49, train_loss: 4.4325, train_perplexity: 142.5038
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.4034, train_perplexity: 141.4896
INFO:root:epoch: 1, train_loss: 2.9202, train_perplexity: 19.9289
INFO:root:epoch: 2, train_loss: 2.2855, train_perplexity: 9.9420
INFO:root:epoch: 3, train_loss: 1.9764, train_perplexity: 7.2836
INFO:root:epoch: 4, train_loss: 1.7388, train_perplexity: 5.7301
INFO:root:epoch: 5, train_loss: 1.5239, train_perplexity: 4.6153
INFO:root:epoch: 6, train_loss: 1.3223, train_perplexity: 3.7695
INFO:root:epoch: 7, train_loss: 1.1381, train_perplexity: 3.1336
INFO:root:epoch: 8, train_loss: 0.9623, train_perplexity: 2.6268
INFO:root:epoch: 9, train_loss: 0.7983, train_perplexity: 2.2287
INFO:root:epoch: 10, train_loss: 0.6455, train_perplexity: 1.9119
INFO:root:epoch: 11, train_loss: 0.5062, train_perplexity: 1.6623
INFO:root:epoch: 12, train_loss: 0.3847, train_perplexity: 1.4712
INFO:root:epoch: 13, train_loss: 0.2838, train_perplexity: 1.3291
INFO:root:epoch: 14, train_loss: 0.2067, train_perplexity: 1.2301
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4178, train_perplexity: 372.3654
INFO:root:epoch: 1, train_loss: 3.8706, train_perplexity: 99.0109
INFO:root:epoch: 2, train_loss: 2.1573, train_perplexity: 9.7290
INFO:root:epoch: 3, train_loss: 2.1699, train_perplexity: 10.0128
INFO:root:epoch: 4, train_loss: 2.0193, train_perplexity: 8.5739
INFO:root:epoch: 5, train_loss: 1.8247, train_perplexity: 6.9372
INFO:root:epoch: 6, train_loss: 1.7107, train_perplexity: 6.1034
INFO:root:epoch: 7, train_loss: 1.6493, train_perplexity: 5.7090
INFO:root:epoch: 8, train_loss: 1.5938, train_perplexity: 5.3770
INFO:root:epoch: 9, train_loss: 1.5378, train_perplexity: 5.0624
INFO:root:epoch: 10, train_loss: 1.4821, train_perplexity: 4.7663
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 2.8343, train_perplexity: 43.1629
INFO:root:epoch: 1, train_loss: 1.6948, train_perplexity: 6.3356
INFO:root:epoch: 2, train_loss: 1.4258, train_perplexity: 4.6455
INFO:root:epoch: 3, train_loss: 1.2352, train_perplexity: 3.7459
INFO:root:epoch: 4, train_loss: 1.0594, train_perplexity: 3.0806
INFO:root:epoch: 5, train_loss: 0.8910, train_perplexity: 2.5619
INFO:root:epoch: 6, train_loss: 0.7229, train_perplexity: 2.1355
INFO:root:epoch: 7, train_loss: 0.5670, train_perplexity: 1.8051
INFO:root:epoch: 8, train_loss: 0.4193, train_perplexity: 1.5419
INFO:root:epoch: 9, train_loss: 0.3068, train_perplexity: 1.3684
INFO:root:epoch: 10, train_loss: 0.2291, train_perplexity: 1.2617
INFO:root:epoch: 11, train_loss: 0.2063, train_perplexity: 1.2314
INFO:root:epoch: 12, train_loss: 0.2040, train_perplexity: 1.2289
INFO:root:epoch: 13, train_loss: 0.2090, train_perplexity: 1.2357
INFO:root:epoch: 14, train_loss: 0.1623, train_perplexity: 1.1784
INFO:root:epoch: 15, train_loss: 0.1148, train_perplexity: 1.1225
INFO:root:epoch: 16, train_loss: 0.0892, train_perplexity: 1.0941
INFO:root:epoch: 17, train_loss: 0.0550, train_perplexity: 1.0566
INFO:root:epoch: 18, train_loss: 0.0374, train_perplexity: 1.0381
INFO:root:epoch: 19, train_loss: 0.0309, train_perplexity: 1.0314
INFO:root:epoch: 20, train_loss: 0.0289, train_perplexity: 1.0294
INFO:root:epoch: 21, train_loss: 0.0274, train_perplexity: 1.0277
INFO:root:epoch: 22, train_loss: 0.0262, train_perplexity: 1.0266
INFO:root:epoch: 23, train_loss: 0.0251, train_perplexity: 1.0254
INFO:root:epoch: 24, train_loss: 0.0242, train_perplexity: 1.0245
INFO:root:epoch: 25, train_loss: 0.0234, train_perplexity: 1.0237
INFO:root:epoch: 26, train_loss: 0.0232, train_perplexity: 1.0235
INFO:root:epoch: 27, train_loss: 0.0231, train_perplexity: 1.0233
INFO:root:epoch: 28, train_loss: 0.0223, train_perplexity: 1.0226
INFO:root:epoch: 29, train_loss: 0.0220, train_perplexity: 1.0222
INFO:root:epoch: 30, train_loss: 0.0216, train_perplexity: 1.0219
INFO:root:epoch: 31, train_loss: 0.0211, train_perplexity: 1.0213
INFO:root:epoch: 32, train_loss: 0.0212, train_perplexity: 1.0214
INFO:root:epoch: 33, train_loss: 0.0207, train_perplexity: 1.0209
INFO:root:epoch: 34, train_loss: 0.0208, train_perplexity: 1.0210
INFO:root:epoch: 35, train_loss: 0.0203, train_perplexity: 1.0205
INFO:root:epoch: 36, train_loss: 0.0201, train_perplexity: 1.0203
INFO:root:epoch: 37, train_loss: 0.0200, train_perplexity: 1.0202
INFO:root:epoch: 38, train_loss: 0.0200, train_perplexity: 1.0202
INFO:root:epoch: 39, train_loss: 0.0199, train_perplexity: 1.0201
INFO:root:epoch: 40, train_loss: 0.0200, train_perplexity: 1.0202
INFO:root:epoch: 41, train_loss: 0.0192, train_perplexity: 1.0194
INFO:root:epoch: 42, train_loss: 0.0196, train_perplexity: 1.0198
INFO:root:epoch: 43, train_loss: 0.0190, train_perplexity: 1.0192
INFO:root:epoch: 44, train_loss: 0.0189, train_perplexity: 1.0191
INFO:root:epoch: 45, train_loss: 0.0187, train_perplexity: 1.0189
INFO:root:epoch: 46, train_loss: 0.0186, train_perplexity: 1.0188
INFO:root:epoch: 47, train_loss: 0.0185, train_perplexity: 1.0186
INFO:root:epoch: 48, train_loss: 0.0185, train_perplexity: 1.0187
INFO:root:epoch: 49, train_loss: 0.0184, train_perplexity: 1.0186
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4178, train_perplexity: 372.3654
INFO:root:epoch: 1, train_loss: 3.8706, train_perplexity: 99.0109
INFO:root:epoch: 2, train_loss: 2.1573, train_perplexity: 9.7290
INFO:root:epoch: 3, train_loss: 2.1699, train_perplexity: 10.0128
INFO:root:epoch: 4, train_loss: 2.0193, train_perplexity: 8.5739
INFO:root:epoch: 5, train_loss: 1.8247, train_perplexity: 6.9372
INFO:root:epoch: 6, train_loss: 1.7107, train_perplexity: 6.1034
INFO:root:epoch: 7, train_loss: 1.6493, train_perplexity: 5.7090
INFO:root:epoch: 8, train_loss: 1.5938, train_perplexity: 5.3770
INFO:root:epoch: 9, train_loss: 1.5378, train_perplexity: 5.0624
INFO:root:epoch: 10, train_loss: 1.4821, train_perplexity: 4.7663
INFO:root:epoch: 11, train_loss: 1.4310, train_perplexity: 4.5105
INFO:root:epoch: 12, train_loss: 1.3833, train_perplexity: 4.2850
INFO:root:epoch: 13, train_loss: 1.3366, train_perplexity: 4.0747
INFO:root:epoch: 14, train_loss: 1.2920, train_perplexity: 3.8833
INFO:root:epoch: 15, train_loss: 1.2498, train_perplexity: 3.7103
INFO:root:epoch: 16, train_loss: 1.2096, train_perplexity: 3.5518
INFO:root:epoch: 17, train_loss: 1.1705, train_perplexity: 3.4047
INFO:root:epoch: 18, train_loss: 1.1323, train_perplexity: 3.2674
INFO:root:epoch: 19, train_loss: 1.0953, train_perplexity: 3.1396
INFO:root:epoch: 20, train_loss: 1.0588, train_perplexity: 3.0186
INFO:root:epoch: 21, train_loss: 1.0228, train_perplexity: 2.9041
INFO:root:epoch: 22, train_loss: 0.9875, train_perplexity: 2.7960
INFO:root:epoch: 23, train_loss: 0.9527, train_perplexity: 2.6935
INFO:root:epoch: 24, train_loss: 0.9184, train_perplexity: 2.5964
INFO:root:epoch: 25, train_loss: 0.8845, train_perplexity: 2.5039
INFO:root:epoch: 26, train_loss: 0.8511, train_perplexity: 2.4161
INFO:root:epoch: 27, train_loss: 0.8179, train_perplexity: 2.3322
INFO:root:epoch: 28, train_loss: 0.7850, train_perplexity: 2.2522
INFO:root:epoch: 29, train_loss: 0.7524, train_perplexity: 2.1758
INFO:root:epoch: 30, train_loss: 0.7201, train_perplexity: 2.1027
INFO:root:epoch: 31, train_loss: 0.6881, train_perplexity: 2.0328
INFO:root:epoch: 32, train_loss: 0.6564, train_perplexity: 1.9661
INFO:root:epoch: 33, train_loss: 0.6250, train_perplexity: 1.9022
INFO:root:epoch: 34, train_loss: 0.5940, train_perplexity: 1.8411
INFO:root:epoch: 35, train_loss: 0.5633, train_perplexity: 1.7828
INFO:root:epoch: 36, train_loss: 0.5331, train_perplexity: 1.7274
INFO:root:epoch: 37, train_loss: 0.5033, train_perplexity: 1.6744
INFO:root:epoch: 38, train_loss: 0.4739, train_perplexity: 1.6239
INFO:root:epoch: 39, train_loss: 0.4452, train_perplexity: 1.5760
INFO:root:epoch: 40, train_loss: 0.4170, train_perplexity: 1.5305
INFO:root:epoch: 41, train_loss: 0.3896, train_perplexity: 1.4876
INFO:root:epoch: 42, train_loss: 0.3628, train_perplexity: 1.4470
INFO:root:epoch: 43, train_loss: 0.3370, train_perplexity: 1.4088
INFO:root:epoch: 44, train_loss: 0.3121, train_perplexity: 1.3731
INFO:root:epoch: 45, train_loss: 0.2882, train_perplexity: 1.3398
INFO:root:epoch: 46, train_loss: 0.2655, train_perplexity: 1.3089
INFO:root:epoch: 47, train_loss: 0.2440, train_perplexity: 1.2803
INFO:root:epoch: 48, train_loss: 0.2236, train_perplexity: 1.2539
INFO:root:epoch: 49, train_loss: 0.2045, train_perplexity: 1.2296
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4178, train_perplexity: 372.3654
INFO:root:epoch: 1, train_loss: 3.8706, train_perplexity: 99.0109
INFO:root:epoch: 2, train_loss: 2.1573, train_perplexity: 9.7290
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 5.4178, train_perplexity: 372.3654
INFO:root:epoch: 1, train_loss: 3.8706, train_perplexity: 99.0109
INFO:root:epoch: 2, train_loss: 2.1573, train_perplexity: 9.7290
INFO:root:epoch: 3, train_loss: 2.1699, train_perplexity: 10.0128
INFO:root:epoch: 4, train_loss: 2.0193, train_perplexity: 8.5739
INFO:root:epoch: 5, train_loss: 1.8247, train_perplexity: 6.9372
INFO:root:epoch: 6, train_loss: 1.7107, train_perplexity: 6.1034
INFO:root:epoch: 7, train_loss: 1.6493, train_perplexity: 5.7090
INFO:root:epoch: 8, train_loss: 1.5938, train_perplexity: 5.3770
INFO:root:epoch: 9, train_loss: 1.5378, train_perplexity: 5.0624
INFO:root:epoch: 10, train_loss: 1.4821, train_perplexity: 4.7663
INFO:root:epoch: 11, train_loss: 1.4310, train_perplexity: 4.5105
INFO:root:epoch: 12, train_loss: 1.3833, train_perplexity: 4.2850
INFO:root:epoch: 13, train_loss: 1.3366, train_perplexity: 4.0747
INFO:root:epoch: 14, train_loss: 1.2920, train_perplexity: 3.8833
INFO:root:epoch: 15, train_loss: 1.2498, train_perplexity: 3.7103
INFO:root:epoch: 16, train_loss: 1.2096, train_perplexity: 3.5518
INFO:root:epoch: 17, train_loss: 1.1705, train_perplexity: 3.4047
INFO:root:epoch: 18, train_loss: 1.1323, train_perplexity: 3.2674
INFO:root:epoch: 19, train_loss: 1.0953, train_perplexity: 3.1396
INFO:root:epoch: 20, train_loss: 1.0588, train_perplexity: 3.0186
INFO:root:epoch: 21, train_loss: 1.0228, train_perplexity: 2.9041
INFO:root:epoch: 22, train_loss: 0.9875, train_perplexity: 2.7960
INFO:root:epoch: 23, train_loss: 0.9527, train_perplexity: 2.6935
INFO:root:epoch: 24, train_loss: 0.9184, train_perplexity: 2.5964
INFO:root:epoch: 25, train_loss: 0.8845, train_perplexity: 2.5039
INFO:root:epoch: 26, train_loss: 0.8511, train_perplexity: 2.4161
INFO:root:epoch: 27, train_loss: 0.8179, train_perplexity: 2.3322
INFO:root:epoch: 28, train_loss: 0.7850, train_perplexity: 2.2522
INFO:root:epoch: 29, train_loss: 0.7524, train_perplexity: 2.1758
INFO:root:epoch: 30, train_loss: 0.7201, train_perplexity: 2.1027
INFO:root:epoch: 31, train_loss: 0.6881, train_perplexity: 2.0328
INFO:root:epoch: 32, train_loss: 0.6564, train_perplexity: 1.9661
INFO:root:epoch: 33, train_loss: 0.6250, train_perplexity: 1.9022
INFO:root:epoch: 34, train_loss: 0.5940, train_perplexity: 1.8411
INFO:root:epoch: 35, train_loss: 0.5633, train_perplexity: 1.7828
INFO:root:epoch: 36, train_loss: 0.5331, train_perplexity: 1.7274
INFO:root:epoch: 37, train_loss: 0.5033, train_perplexity: 1.6744
INFO:root:epoch: 38, train_loss: 0.4739, train_perplexity: 1.6239
INFO:root:epoch: 39, train_loss: 0.4452, train_perplexity: 1.5760
INFO:root:epoch: 40, train_loss: 0.4170, train_perplexity: 1.5305
INFO:root:epoch: 41, train_loss: 0.3896, train_perplexity: 1.4876
INFO:root:epoch: 42, train_loss: 0.3628, train_perplexity: 1.4470
INFO:root:epoch: 43, train_loss: 0.3370, train_perplexity: 1.4088
INFO:root:epoch: 44, train_loss: 0.3121, train_perplexity: 1.3731
INFO:root:epoch: 45, train_loss: 0.2882, train_perplexity: 1.3398
INFO:root:epoch: 46, train_loss: 0.2655, train_perplexity: 1.3089
INFO:root:epoch: 47, train_loss: 0.2440, train_perplexity: 1.2803
INFO:root:epoch: 48, train_loss: 0.2236, train_perplexity: 1.2539
INFO:root:epoch: 49, train_loss: 0.2045, train_perplexity: 1.2296
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 256, 'batch_size': 16, 'gradient_accumulations': 4, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 50, 'max_seq_len': 512, 'batch_size': 4, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 4.8273, train_perplexity: 323.9079
INFO:root:epoch: 1, train_loss: 1.9618, train_perplexity: 10.5466
INFO:root:epoch: 2, train_loss: 1.8514, train_perplexity: 8.4194
INFO:root:epoch: 3, train_loss: 1.5906, train_perplexity: 5.9651
INFO:root:epoch: 4, train_loss: 1.4911, train_perplexity: 5.2642
INFO:root:epoch: 5, train_loss: 1.4141, train_perplexity: 4.8062
INFO:root:epoch: 6, train_loss: 1.3425, train_perplexity: 4.4286
INFO:root:epoch: 7, train_loss: 1.2779, train_perplexity: 4.1162
INFO:root:epoch: 8, train_loss: 1.2207, train_perplexity: 3.8569
INFO:root:epoch: 9, train_loss: 1.1693, train_perplexity: 3.6343
INFO:root:epoch: 10, train_loss: 1.1216, train_perplexity: 3.4409
INFO:root:epoch: 11, train_loss: 1.0764, train_perplexity: 3.2667
INFO:root:epoch: 12, train_loss: 1.0337, train_perplexity: 3.1096
INFO:root:epoch: 13, train_loss: 0.9928, train_perplexity: 2.9660
INFO:root:epoch: 14, train_loss: 0.9528, train_perplexity: 2.8316
INFO:root:epoch: 15, train_loss: 0.9137, train_perplexity: 2.7065
INFO:root:epoch: 16, train_loss: 0.8755, train_perplexity: 2.5898
INFO:root:epoch: 17, train_loss: 0.8378, train_perplexity: 2.4801
INFO:root:epoch: 18, train_loss: 0.8002, train_perplexity: 2.3760
INFO:root:epoch: 19, train_loss: 0.7631, train_perplexity: 2.2777
INFO:root:epoch: 20, train_loss: 0.7262, train_perplexity: 2.1845
INFO:root:epoch: 21, train_loss: 0.6894, train_perplexity: 2.0956
INFO:root:epoch: 22, train_loss: 0.6527, train_perplexity: 2.0108
INFO:root:epoch: 23, train_loss: 0.6160, train_perplexity: 1.9299
INFO:root:epoch: 24, train_loss: 0.5795, train_perplexity: 1.8531
INFO:root:epoch: 25, train_loss: 0.5432, train_perplexity: 1.7799
INFO:root:epoch: 26, train_loss: 0.5071, train_perplexity: 1.7103
INFO:root:epoch: 27, train_loss: 0.4713, train_perplexity: 1.6443
INFO:root:epoch: 28, train_loss: 0.4360, train_perplexity: 1.5820
INFO:root:epoch: 29, train_loss: 0.4013, train_perplexity: 1.5233
INFO:root:epoch: 30, train_loss: 0.3674, train_perplexity: 1.4683
INFO:root:epoch: 31, train_loss: 0.3345, train_perplexity: 1.4169
INFO:root:epoch: 32, train_loss: 0.3026, train_perplexity: 1.3693
INFO:root:epoch: 33, train_loss: 0.2722, train_perplexity: 1.3255
INFO:root:epoch: 34, train_loss: 0.2433, train_perplexity: 1.2854
INFO:root:epoch: 35, train_loss: 0.2163, train_perplexity: 1.2491
INFO:root:epoch: 36, train_loss: 0.1911, train_perplexity: 1.2164
INFO:root:epoch: 37, train_loss: 0.1680, train_perplexity: 1.1874
INFO:root:epoch: 38, train_loss: 0.1472, train_perplexity: 1.1619
INFO:root:epoch: 39, train_loss: 0.1285, train_perplexity: 1.1396
INFO:root:epoch: 40, train_loss: 0.1120, train_perplexity: 1.1203
INFO:root:epoch: 41, train_loss: 0.0975, train_perplexity: 1.1037
INFO:root:epoch: 42, train_loss: 0.0850, train_perplexity: 1.0897
INFO:root:epoch: 43, train_loss: 0.0744, train_perplexity: 1.0779
INFO:root:epoch: 44, train_loss: 0.0655, train_perplexity: 1.0681
INFO:root:epoch: 45, train_loss: 0.0579, train_perplexity: 1.0599
INFO:root:epoch: 46, train_loss: 0.0518, train_perplexity: 1.0534
INFO:root:epoch: 47, train_loss: 0.0469, train_perplexity: 1.0482
INFO:root:epoch: 48, train_loss: 0.0429, train_perplexity: 1.0440
INFO:root:epoch: 49, train_loss: 0.0390, train_perplexity: 1.0399
INFO:root:cfg: {'experiment_name': 'speaker_name_as_prompt_deneme', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets/processed_df.csv', 'log_dir': '../logs', 'checkpoint_dir': '../checkpoints', 'epochs': 5, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 0.0001}
INFO:root:Using device: cuda:0
INFO:root:train data loaded.
INFO:root:epoch: 0, train_loss: 1.6627, train_perplexity: 6.5904
INFO:root:epoch: 1, train_loss: 1.5347, train_perplexity: 5.2950
INFO:root:epoch: 2, train_loss: 1.4740, train_perplexity: 4.9483
INFO:root:epoch: 3, train_loss: 1.4230, train_perplexity: 4.6733
INFO:root:epoch: 4, train_loss: 1.3762, train_perplexity: 4.4342
