19-07-2022 16:08  - cfg: {'model': 'k2t', 'experiment_name': '19july_k2t_gpt2medium_maxseqlen256_batch8_8_lr2e5', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets', 'log_dir': '../logs', 'checkpoint_dir': '/cluster/scratch/goezsoy/nlp_lss_checkpoints', 'epochs': 10, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 2e-05, 'print_iter_freq': 500, 'prefix_len': 10, 'embed_size_per_token': 500, 'speaker_size': 28, 'freeze_gpt': False, 'encoded': 'encoded_parl_part_ids', 'latent_dim': 100, 'kl_weight': 1000.0, 'use_annealing': True, 'annealing_period': 200, 'party': 'all'}
19-07-2022 16:08  - Using device: cuda:0
19-07-2022 16:15  - train data loaded.
19-07-2022 16:16  - valid data loaded.

19-07-2022 16:17  - epoch: 1 / 10
19-07-2022 16:43  - iter: 500 / 2898, iter_loss: 1.5437, iter_perplexity: 5.1793
19-07-2022 17:15  - cfg: {'model': 'k2t', 'experiment_name': '19july_k2t_gpt2medium_maxseqlen256_batch8_8_lr2e5', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets', 'log_dir': '../logs', 'checkpoint_dir': '/cluster/scratch/goezsoy/nlp_lss_checkpoints', 'epochs': 10, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 2e-05, 'print_iter_freq': 500, 'prefix_len': 10, 'embed_size_per_token': 500, 'speaker_size': 28, 'freeze_gpt': False, 'encoded': 'encoded_parl_part_ids', 'latent_dim': 100, 'kl_weight': 1000.0, 'use_annealing': True, 'annealing_period': 200, 'party': 'all'}
19-07-2022 17:15  - Using device: cuda:0
19-07-2022 17:23  - train data loaded.
19-07-2022 17:25  - valid data loaded.

19-07-2022 17:26  - epoch: 1 / 10
19-07-2022 18:09  - cfg: {'model': 'k2t', 'experiment_name': '19july_k2t_gpt2medium_maxseqlen256_batch8_8_lr2e5', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets', 'log_dir': '../logs', 'checkpoint_dir': '/cluster/scratch/goezsoy/nlp_lss_checkpoints', 'epochs': 10, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 2e-05, 'print_iter_freq': 500, 'prefix_len': 10, 'embed_size_per_token': 500, 'speaker_size': 28, 'freeze_gpt': False, 'encoded': 'encoded_parl_part_ids', 'latent_dim': 100, 'kl_weight': 1000.0, 'use_annealing': True, 'annealing_period': 200, 'party': 'all'}
19-07-2022 18:09  - Using device: cuda:0
19-07-2022 18:17  - cfg: {'model': 'k2t', 'experiment_name': '19july_k2t_gpt2medium_maxseqlen256_batch8_8_lr2e5', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets', 'log_dir': '../logs', 'checkpoint_dir': '/cluster/scratch/goezsoy/nlp_lss_checkpoints', 'epochs': 10, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 2e-05, 'print_iter_freq': 500, 'prefix_len': 10, 'embed_size_per_token': 500, 'speaker_size': 28, 'freeze_gpt': False, 'encoded': 'encoded_parl_part_ids', 'latent_dim': 100, 'kl_weight': 1000.0, 'use_annealing': True, 'annealing_period': 200, 'party': 'all'}
19-07-2022 18:17  - Using device: cuda:0
19-07-2022 18:24  - train data loaded.
19-07-2022 18:25  - valid data loaded.

19-07-2022 18:25  - epoch: 1 / 10
19-07-2022 18:51  - iter: 500 / 2898, iter_loss: 1.6252, iter_perplexity: 5.9916
19-07-2022 19:16  - iter: 1000 / 2898, iter_loss: 1.5615, iter_perplexity: 4.9164
19-07-2022 19:37  - cfg: {'model': 'k2t', 'experiment_name': '19july_k2t_gpt2medium_maxseqlen256_batch8_8_lr2e5', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets', 'log_dir': '../logs', 'checkpoint_dir': '/cluster/scratch/goezsoy/nlp_lss_checkpoints', 'epochs': 10, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 2e-05, 'print_iter_freq': 500, 'prefix_len': 10, 'embed_size_per_token': 500, 'speaker_size': 28, 'freeze_gpt': False, 'encoded': 'encoded_parl_part_ids', 'latent_dim': 100, 'kl_weight': 1000.0, 'use_annealing': True, 'annealing_period': 200, 'party': 'all'}
19-07-2022 19:37  - Using device: cuda:0
19-07-2022 19:44  - train data loaded.
19-07-2022 19:45  - valid data loaded.

19-07-2022 19:45  - epoch: 1 / 10
19-07-2022 20:12  - iter: 500 / 2898, iter_loss: 1.5094, iter_perplexity: 4.6875
19-07-2022 20:37  - iter: 1000 / 2898, iter_loss: 1.3490, iter_perplexity: 4.2661
19-07-2022 21:03  - iter: 1500 / 2898, iter_loss: 1.5434, iter_perplexity: 5.0214
19-07-2022 21:29  - iter: 2000 / 2898, iter_loss: 1.5601, iter_perplexity: 5.0806
19-07-2022 21:54  - iter: 2500 / 2898, iter_loss: 1.3979, iter_perplexity: 4.1903
19-07-2022 22:19  - epoch: 1 / 10, train_loss: 1.5018, train_perplexity: 7.1447, val_loss: 1.4078, val_perplexity: 4.3933

19-07-2022 22:19  - epoch: 2 / 10
19-07-2022 22:45  - iter: 500 / 2898, iter_loss: 1.4617, iter_perplexity: 4.8179
19-07-2022 23:11  - iter: 1000 / 2898, iter_loss: 1.2349, iter_perplexity: 3.5841
19-07-2022 23:36  - iter: 1500 / 2898, iter_loss: 1.5001, iter_perplexity: 4.5725
20-07-2022 00:02  - iter: 2000 / 2898, iter_loss: 1.2578, iter_perplexity: 4.0282
20-07-2022 00:28  - iter: 2500 / 2898, iter_loss: 1.6014, iter_perplexity: 5.2122
20-07-2022 00:53  - epoch: 2 / 10, train_loss: 1.4097, train_perplexity: 4.4040, val_loss: 1.3827, val_perplexity: 4.2903

20-07-2022 00:53  - epoch: 3 / 10
20-07-2022 01:19  - iter: 500 / 2898, iter_loss: 1.2878, iter_perplexity: 4.1104
20-07-2022 01:45  - iter: 1000 / 2898, iter_loss: 1.3948, iter_perplexity: 4.4360
20-07-2022 02:10  - iter: 1500 / 2898, iter_loss: 1.3139, iter_perplexity: 3.8315
20-07-2022 02:36  - iter: 2000 / 2898, iter_loss: 1.3188, iter_perplexity: 3.8890
20-07-2022 03:01  - iter: 2500 / 2898, iter_loss: 1.2190, iter_perplexity: 3.4334
20-07-2022 03:27  - epoch: 3 / 10, train_loss: 1.3745, train_perplexity: 4.2445, val_loss: 1.3700, val_perplexity: 4.2327

20-07-2022 03:27  - epoch: 4 / 10
20-07-2022 03:53  - iter: 500 / 2898, iter_loss: 1.4375, iter_perplexity: 4.3624
20-07-2022 04:18  - iter: 1000 / 2898, iter_loss: 1.3480, iter_perplexity: 4.0711
20-07-2022 04:44  - iter: 1500 / 2898, iter_loss: 1.3083, iter_perplexity: 4.0131
20-07-2022 05:10  - iter: 2000 / 2898, iter_loss: 1.3075, iter_perplexity: 3.9764
20-07-2022 05:36  - iter: 2500 / 2898, iter_loss: 1.5358, iter_perplexity: 4.7297
20-07-2022 06:01  - epoch: 4 / 10, train_loss: 1.3487, train_perplexity: 4.1254, val_loss: 1.3611, val_perplexity: 4.1859

20-07-2022 06:01  - epoch: 5 / 10
20-07-2022 06:27  - iter: 500 / 2898, iter_loss: 1.3613, iter_perplexity: 3.9983
20-07-2022 06:53  - iter: 1000 / 2898, iter_loss: 1.3099, iter_perplexity: 4.1317
20-07-2022 07:19  - iter: 1500 / 2898, iter_loss: 1.3242, iter_perplexity: 3.8936
20-07-2022 07:45  - iter: 2000 / 2898, iter_loss: 1.3068, iter_perplexity: 3.7454
20-07-2022 08:11  - iter: 2500 / 2898, iter_loss: 1.3503, iter_perplexity: 4.0728
20-07-2022 08:36  - epoch: 5 / 10, train_loss: 1.3282, train_perplexity: 4.0386, val_loss: 1.3560, val_perplexity: 4.1562

20-07-2022 08:36  - epoch: 6 / 10
20-07-2022 09:02  - iter: 500 / 2898, iter_loss: 1.3748, iter_perplexity: 4.1079
20-07-2022 09:28  - iter: 1000 / 2898, iter_loss: 1.5355, iter_perplexity: 5.0214
20-07-2022 09:53  - iter: 1500 / 2898, iter_loss: 1.3031, iter_perplexity: 4.0306
20-07-2022 10:19  - iter: 2000 / 2898, iter_loss: 1.2318, iter_perplexity: 3.4822
20-07-2022 10:45  - iter: 2500 / 2898, iter_loss: 1.2540, iter_perplexity: 3.8032
20-07-2022 11:10  - epoch: 6 / 10, train_loss: 1.3102, train_perplexity: 3.9582, val_loss: 1.3515, val_perplexity: 4.1523

20-07-2022 11:10  - epoch: 7 / 10
20-07-2022 11:36  - iter: 500 / 2898, iter_loss: 1.2349, iter_perplexity: 3.5902
20-07-2022 12:02  - iter: 1000 / 2898, iter_loss: 1.4639, iter_perplexity: 4.5958
20-07-2022 12:27  - iter: 1500 / 2898, iter_loss: 1.3014, iter_perplexity: 3.7908
20-07-2022 12:53  - iter: 2000 / 2898, iter_loss: 1.5391, iter_perplexity: 4.8411
20-07-2022 13:19  - iter: 2500 / 2898, iter_loss: 1.3870, iter_perplexity: 4.2820
20-07-2022 13:44  - epoch: 7 / 10, train_loss: 1.2937, train_perplexity: 3.8902, val_loss: 1.3485, val_perplexity: 4.1237

20-07-2022 13:44  - epoch: 8 / 10
20-07-2022 14:10  - iter: 500 / 2898, iter_loss: 1.2812, iter_perplexity: 3.8254
20-07-2022 14:35  - iter: 1000 / 2898, iter_loss: 1.2757, iter_perplexity: 3.7957
20-07-2022 15:01  - iter: 1500 / 2898, iter_loss: 1.2287, iter_perplexity: 3.6495
20-07-2022 15:27  - iter: 2000 / 2898, iter_loss: 1.3113, iter_perplexity: 4.1252
20-07-2022 15:54  - iter: 2500 / 2898, iter_loss: 1.3066, iter_perplexity: 3.8176
20-07-2022 16:19  - epoch: 8 / 10, train_loss: 1.2782, train_perplexity: 3.8234, val_loss: 1.3469, val_perplexity: 4.1279

20-07-2022 16:19  - epoch: 9 / 10
20-07-2022 16:45  - iter: 500 / 2898, iter_loss: 1.1602, iter_perplexity: 3.2464
20-07-2022 17:10  - iter: 1000 / 2898, iter_loss: 1.1488, iter_perplexity: 3.3828
20-07-2022 17:36  - iter: 1500 / 2898, iter_loss: 1.4061, iter_perplexity: 4.4299
20-07-2022 18:02  - iter: 2000 / 2898, iter_loss: 1.1415, iter_perplexity: 3.5775
20-07-2022 18:27  - iter: 2500 / 2898, iter_loss: 1.3034, iter_perplexity: 4.0874
