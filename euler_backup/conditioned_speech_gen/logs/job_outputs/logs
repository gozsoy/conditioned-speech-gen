Sender: LSF System <lsfadmin@eu-lo-g2-015>
Subject: Job 218317651: <python main.py --config ../config.yml> in cluster <euler> Exited

Job <python main.py --config ../config.yml> was submitted from host <eu-login-14> by user <goezsoy> in cluster <euler> at Fri May 13 10:40:55 2022
Job was executed on host(s) <4*eu-lo-g2-015>, in queue <gpu.4h>, as user <goezsoy> in cluster <euler> at Fri May 13 10:41:23 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/conditioned_speech_gen/src> was used as the working directory.
Started at Fri May 13 10:41:23 2022
Terminated at Fri May 13 10:43:06 2022
Results reported at Fri May 13 10:43:06 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   24.40 sec.
    Max Memory :                                 5281 MB
    Average Memory :                             2356.50 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               11103.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                9
    Run time :                                   102 sec.
    Turnaround time :                            131 sec.

The output (if any) follows:

2022-05-13 10:41:48.017293: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
  0%|          | 0/38 [00:00<?, ?ex/s] 71%|███████   | 27/38 [00:00<00:00, 259.49ex/s]100%|██████████| 38/38 [00:00<00:00, 230.29ex/s]
Traceback (most recent call last):
  File "main.py", line 92, in <module>
    train(cfg, device)
  File "main.py", line 37, in train
    loss,logits = net(batch_data.to(device))
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/conditioned_speech_gen/src/model.py", line 13, in forward
    outputs = self.gpt_neo(**inputs, labels=inputs.input_ids)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 739, in forward
    transformer_outputs = self.transformer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 618, in forward
    outputs = block(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 323, in forward
    attn_outputs = self.attn(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 275, in forward
    return self.attention(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 238, in forward
    attn_output, attn_weights = self._attn(query, key, value, attention_mask, head_mask)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 187, in _attn
    attn_weights = torch.matmul(query, key.transpose(-1, -2))
RuntimeError: CUDA out of memory. Tried to allocate 234.00 MiB (GPU 0; 10.76 GiB total capacity; 9.33 GiB already allocated; 35.56 MiB free; 9.49 GiB reserved in total by PyTorch)
Sender: LSF System <lsfadmin@eu-lo-g2-015>
Subject: Job 218317977: <python main.py --config ../config.yml> in cluster <euler> Exited

Job <python main.py --config ../config.yml> was submitted from host <eu-login-14> by user <goezsoy> in cluster <euler> at Fri May 13 10:44:09 2022
Job was executed on host(s) <4*eu-lo-g2-015>, in queue <gpu.4h>, as user <goezsoy> in cluster <euler> at Fri May 13 10:44:22 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/conditioned_speech_gen/src> was used as the working directory.
Started at Fri May 13 10:44:22 2022
Terminated at Fri May 13 10:46:03 2022
Results reported at Fri May 13 10:46:03 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   24.87 sec.
    Max Memory :                                 5282 MB
    Average Memory :                             2658.17 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               11102.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                9
    Run time :                                   127 sec.
    Turnaround time :                            114 sec.

The output (if any) follows:

2022-05-13 10:44:44.841320: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
  0%|          | 0/38 [00:00<?, ?ex/s] 68%|██████▊   | 26/38 [00:00<00:00, 254.74ex/s]100%|██████████| 38/38 [00:00<00:00, 227.43ex/s]
Traceback (most recent call last):
  File "main.py", line 92, in <module>
    train(cfg, device)
  File "main.py", line 37, in train
    loss,logits = net(batch_data.to(device))
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/conditioned_speech_gen/src/model.py", line 13, in forward
    outputs = self.gpt_neo(**inputs, labels=inputs.input_ids)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 739, in forward
    transformer_outputs = self.transformer(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 618, in forward
    outputs = block(
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 338, in forward
    feed_forward_hidden_states = self.mlp(hidden_states)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/models/gpt_neo/modeling_gpt_neo.py", line 296, in forward
    hidden_states = self.act(hidden_states)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/nn/modules/module.py", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File "/cluster/home/goezsoy/.local/lib/python3.8/site-packages/transformers/activations.py", line 34, in forward
    return 0.5 * input * (1.0 + torch.tanh(math.sqrt(2.0 / math.pi) * (input + 0.044715 * torch.pow(input, 3.0))))
RuntimeError: CUDA out of memory. Tried to allocate 54.00 MiB (GPU 0; 10.76 GiB total capacity; 9.08 GiB already allocated; 45.56 MiB free; 9.48 GiB reserved in total by PyTorch)
Sender: LSF System <lsfadmin@eu-lo-g2-020>
Subject: Job 218319179: <python main.py --config ../config.yml> in cluster <euler> Exited

Job <python main.py --config ../config.yml> was submitted from host <eu-login-14> by user <goezsoy> in cluster <euler> at Fri May 13 10:51:34 2022
Job was executed on host(s) <4*eu-lo-g2-020>, in queue <gpu.4h>, as user <goezsoy> in cluster <euler> at Fri May 13 10:51:52 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/conditioned_speech_gen/src> was used as the working directory.
Started at Fri May 13 10:51:52 2022
Terminated at Fri May 13 10:53:39 2022
Results reported at Fri May 13 10:53:39 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py --config ../config.yml
------------------------------------------------------------

Exited with exit code 1.

Resource usage summary:

    CPU time :                                   27.17 sec.
    Max Memory :                                 5458 MB
    Average Memory :                             1510.50 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               10926.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                7
    Run time :                                   107 sec.
    Turnaround time :                            125 sec.

The output (if any) follows:

2022-05-13 10:52:17.695244: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
  0%|          | 0/38 [00:00<?, ?ex/s] 71%|███████   | 27/38 [00:00<00:00, 260.33ex/s]100%|██████████| 38/38 [00:00<00:00, 230.11ex/s]
Traceback (most recent call last):
  File "main.py", line 92, in <module>
    train(cfg, device)
  File "main.py", line 40, in train
    loss.backward()
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/tensor.py", line 221, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File "/cluster/apps/nss/gcc-6.3.0/python_gpu/3.8.5/torch/autograd/__init__.py", line 130, in backward
    Variable._execution_engine.run_backward(
RuntimeError: CUDA out of memory. Tried to allocate 524.00 MiB (GPU 0; 10.76 GiB total capacity; 8.12 GiB already allocated; 353.56 MiB free; 9.18 GiB reserved in total by PyTorch)
Sender: LSF System <lsfadmin@eu-lo-s4-019>
Subject: Job 218320056: <python main.py --config ../config.yml> in cluster <euler> Done

Job <python main.py --config ../config.yml> was submitted from host <eu-login-14> by user <goezsoy> in cluster <euler> at Fri May 13 10:55:50 2022
Job was executed on host(s) <4*eu-lo-s4-019>, in queue <gpu.4h>, as user <goezsoy> in cluster <euler> at Fri May 13 10:56:22 2022
</cluster/home/goezsoy> was used as the home directory.
</cluster/home/goezsoy/conditioned_speech_gen/src> was used as the working directory.
Started at Fri May 13 10:56:22 2022
Terminated at Fri May 13 11:21:28 2022
Results reported at Fri May 13 11:21:28 2022

Your job looked like:

------------------------------------------------------------
# LSBATCH: User input
python main.py --config ../config.yml
------------------------------------------------------------

Successfully completed.

Resource usage summary:

    CPU time :                                   1126.62 sec.
    Max Memory :                                 8407 MB
    Average Memory :                             7438.67 MB
    Total Requested Memory :                     16384.00 MB
    Delta Memory :                               7977.00 MB
    Max Swap :                                   -
    Max Processes :                              3
    Max Threads :                                10
    Run time :                                   1506 sec.
    Turnaround time :                            1538 sec.

The output (if any) follows:

2022-05-13 10:56:47.896186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0
  0%|          | 0/38 [00:00<?, ?ex/s] 58%|█████▊    | 22/38 [00:00<00:00, 206.97ex/s]100%|██████████| 38/38 [00:00<00:00, 192.21ex/s]
