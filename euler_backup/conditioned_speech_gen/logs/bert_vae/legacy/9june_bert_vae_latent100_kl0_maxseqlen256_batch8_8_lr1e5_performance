09-06-2022 11:08  - cfg: {'model': 'bert_vae', 'experiment_name': '9june_bert_vae_latent100_kl0_maxseqlen256_batch8_8_lr1e5', 'data_path': '/cluster/scratch/goezsoy/nlp_lss_datasets', 'log_dir': '../logs', 'checkpoint_dir': '/cluster/scratch/goezsoy/nlp_lss_checkpoints', 'epochs': 100, 'max_seq_len': 256, 'batch_size': 8, 'gradient_accumulations': 8, 'learning_rate': 1e-05, 'print_iter_freq': 50, 'prefix_len': 10, 'embed_size_per_token': 500, 'speaker_size': 28, 'freeze_gpt': False, 'encoded': 'encoded_parl_part_ids', 'latent_dim': 100, 'kl_weight': 0.0}
09-06-2022 11:08  - Using device: cuda:0
09-06-2022 11:08  - train data loaded.
09-06-2022 11:08  - valid data loaded.

09-06-2022 11:09  - epoch: 1 / 100
09-06-2022 11:10  - epoch: 1 / 100, train_rec_loss: 7.2639, train_kl_loss: 0.0000, train_perplexity: 3152.1454

09-06-2022 11:10  - epoch: 2 / 100
09-06-2022 11:11  - epoch: 2 / 100, train_rec_loss: 6.0125, train_kl_loss: 0.0000, train_perplexity: 433.8340

09-06-2022 11:11  - epoch: 3 / 100
09-06-2022 11:12  - epoch: 3 / 100, train_rec_loss: 5.0065, train_kl_loss: 0.0000, train_perplexity: 156.7655

09-06-2022 11:12  - epoch: 4 / 100
09-06-2022 11:13  - epoch: 4 / 100, train_rec_loss: 4.0934, train_kl_loss: 0.0000, train_perplexity: 62.9616

09-06-2022 11:13  - epoch: 5 / 100
09-06-2022 11:14  - epoch: 5 / 100, train_rec_loss: 3.3118, train_kl_loss: 0.0000, train_perplexity: 28.4397

09-06-2022 11:14  - epoch: 6 / 100
09-06-2022 11:15  - epoch: 6 / 100, train_rec_loss: 2.6908, train_kl_loss: 0.0000, train_perplexity: 15.1975

09-06-2022 11:15  - epoch: 7 / 100
09-06-2022 11:16  - epoch: 7 / 100, train_rec_loss: 2.1513, train_kl_loss: 0.0000, train_perplexity: 8.7854

09-06-2022 11:16  - epoch: 8 / 100
09-06-2022 11:17  - epoch: 8 / 100, train_rec_loss: 1.6925, train_kl_loss: 0.0000, train_perplexity: 5.5343

09-06-2022 11:17  - epoch: 9 / 100
09-06-2022 11:18  - epoch: 9 / 100, train_rec_loss: 1.3460, train_kl_loss: 0.0000, train_perplexity: 3.8903

09-06-2022 11:18  - epoch: 10 / 100
09-06-2022 11:19  - epoch: 10 / 100, train_rec_loss: 1.0922, train_kl_loss: 0.0000, train_perplexity: 3.0096

09-06-2022 11:19  - epoch: 11 / 100
09-06-2022 11:20  - epoch: 11 / 100, train_rec_loss: 0.8924, train_kl_loss: 0.0000, train_perplexity: 2.4623

09-06-2022 11:20  - epoch: 12 / 100
09-06-2022 11:21  - epoch: 12 / 100, train_rec_loss: 0.7345, train_kl_loss: 0.0000, train_perplexity: 2.1007

09-06-2022 11:21  - epoch: 13 / 100
09-06-2022 11:22  - epoch: 13 / 100, train_rec_loss: 0.6557, train_kl_loss: 0.0000, train_perplexity: 1.9407

09-06-2022 11:22  - epoch: 14 / 100
09-06-2022 11:23  - epoch: 14 / 100, train_rec_loss: 0.5489, train_kl_loss: 0.0000, train_perplexity: 1.7395

09-06-2022 11:23  - epoch: 15 / 100
09-06-2022 11:24  - epoch: 15 / 100, train_rec_loss: 0.4661, train_kl_loss: 0.0000, train_perplexity: 1.6012

09-06-2022 11:24  - epoch: 16 / 100
09-06-2022 11:26  - epoch: 16 / 100, train_rec_loss: 0.4136, train_kl_loss: 0.0000, train_perplexity: 1.5182

09-06-2022 11:26  - epoch: 17 / 100
09-06-2022 11:27  - epoch: 17 / 100, train_rec_loss: 0.3421, train_kl_loss: 0.0000, train_perplexity: 1.4114

09-06-2022 11:27  - epoch: 18 / 100
09-06-2022 11:28  - epoch: 18 / 100, train_rec_loss: 0.3094, train_kl_loss: 0.0000, train_perplexity: 1.3652

09-06-2022 11:28  - epoch: 19 / 100
09-06-2022 11:29  - epoch: 19 / 100, train_rec_loss: 0.2693, train_kl_loss: 0.0000, train_perplexity: 1.3110

09-06-2022 11:29  - epoch: 20 / 100
09-06-2022 11:30  - epoch: 20 / 100, train_rec_loss: 0.2461, train_kl_loss: 0.0000, train_perplexity: 1.2809

09-06-2022 11:30  - epoch: 21 / 100
09-06-2022 11:31  - epoch: 21 / 100, train_rec_loss: 0.2148, train_kl_loss: 0.0000, train_perplexity: 1.2408

09-06-2022 11:31  - epoch: 22 / 100
09-06-2022 11:32  - epoch: 22 / 100, train_rec_loss: 0.2054, train_kl_loss: 0.0000, train_perplexity: 1.2301

09-06-2022 11:32  - epoch: 23 / 100
09-06-2022 11:33  - epoch: 23 / 100, train_rec_loss: 0.1896, train_kl_loss: 0.0000, train_perplexity: 1.2100

09-06-2022 11:33  - epoch: 24 / 100
09-06-2022 11:34  - epoch: 24 / 100, train_rec_loss: 0.1665, train_kl_loss: 0.0000, train_perplexity: 1.1824

09-06-2022 11:34  - epoch: 25 / 100
09-06-2022 11:35  - epoch: 25 / 100, train_rec_loss: 0.1486, train_kl_loss: 0.0000, train_perplexity: 1.1609

09-06-2022 11:35  - epoch: 26 / 100
