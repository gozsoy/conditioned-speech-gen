{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gokberk/miniconda3/envs/ml4hc_project2/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt options:\n",
    "# Joyce Beatty\n",
    "# Joyce Beatty says the following:\n",
    "# Joyce Beatty says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=300,\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]'''\n",
    "\n",
    "'''import numpy as np\n",
    "tokenizer.decode(np.argmax(outputs.logits.detach().numpy(),axis=2)[0])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read whole corpus\n",
    "processed_df = pd.read_pickle('../data/processed_df.pkl')\n",
    "\n",
    "# work on subset of speakers\n",
    "temp_bioguides = ['H001055','C001074']\n",
    "temp_df = processed_df[processed_df.bioguide_id.isin(temp_bioguides)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_row = temp_df.iloc[0]\n",
    "\n",
    "prompt = temp_row['first_name'] + ' ' + temp_row['last_name'] + ' ' + temp_row['speech']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.functional as F\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.gpt_neo = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        inputs = self.tokenizer(x, return_tensors=\"pt\")\n",
    "        outputs = self.gpt_neo(**inputs, labels=inputs.input_ids)\n",
    "        \n",
    "        return outputs.loss,outputs.logits\n",
    "\n",
    "\n",
    "net = Net()\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.62884783744812\n",
      "1.0245797634124756\n",
      "0.5738399624824524\n",
      "0.27172327041625977\n",
      "0.13085439801216125\n",
      "0.06838947534561157\n",
      "0.023092877119779587\n",
      "0.004251773934811354\n",
      "0.002531480509787798\n",
      "0.001702785142697394\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    #for i, data in enumerate(trainloader, 0):\n",
    "\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    loss,logits = net(prompt)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "inputs = net.tokenizer(temp_row['first_name'] + ' ' + temp_row['last_name'], return_tensors=\"pt\")\n",
    "gen_tokens = net.gpt_neo.generate(\n",
    "    inputs.input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=300,\n",
    ")\n",
    "gen_text = net.tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.tokenizer.pad_token = net.tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 15:32:27.167877: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       "array([[   51, 16956,  5932,   364],\n",
       "       [   51, 16956, 50256, 50256]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 4), dtype=int32, numpy=\n",
       "array([[1, 1, 1, 1],\n",
       "       [1, 1, 0, 0]], dtype=int32)>}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.tokenizer([temp_row['first_name'] + ' ' + temp_row['last_name'],temp_row['first_name']],padding=True,return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show it works for temporary data, then report it quickly"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ad60ff5a86e10c0b348d0515e5915c96ce4bb92811ed18f12804eec31c34dafe"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('nlp_lss')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
